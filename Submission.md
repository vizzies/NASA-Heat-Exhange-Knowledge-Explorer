## Challenge A - Paper Clustering  
* The Problem: As the already surging rate of scientific literature publishing continues to grow exponentially,  it has become increasingly difficult and time-consuming for researchers to gather the necessary resources for interdisciplinary cross collaboration, even with the use of current sophisticated search tools (as they do not identify and dsiplay subtopic relations and the extent of research).
* Our Project: The team explored several methods to improve topic modeling results generated by Latent Dirichlet Allocation (LDA). All methods focused on improving the postprocessing and cleaning of PDFs or derived datasets.Â 
* Results: While results are inconclusive, the relevant terms displayed by pyLDAViz appear to be more relevant to heat exchangers.

## Process Overview and Implementation  
* The team's strategy was developed based off the initial results from the Challenge A starter notebook. Relevant terms appearing in the distance mao included special characters only (e.g. "--"), alphanumeric phrases, or incomplete words such as single letters.
* To solve the problem, we looked at additional postprocessing methods to further clean the data before creating a bag-of-words using scikit-learn's `CountVectorizer`
	* Improved text extraction from PDF's using PDFMiner
	* Removal of irrelevant characters and text using regular expressions
	* Extracting nouns from datasets exported by Watson Explorer
* Because the team felt it was best to focus on data cleaning, the final work is a series of Jupyter Notebooks, each highlighting a specific method. Some notebooks, such as Watson Explorer postprocessing, combine postprocessing steps.

## Dependencies and Outputs  
* Dependencies
	* Generated the.txt version of each PDF  
	* [PDF Parser](https://github.com/vizzies/grcml-challenge-a-starter/blob/main/Scripts/batch_pdf_parser.py)  
	* [Python Element Tree Parser](https://docs.python.org/3/library/xml.etree.elementtree.html)  
	* [Camelot](https://github.com/atlanhq/camelot)  

* Output
	* [New Combined Output Text](https://github.com/vizzies/grcml-challenge-a-starter/blob/main/Processed/Combined_Output.txt)

* Artifacts Produced
	* [Project Code Repository](https://github.com/vizzies/NASA-Heat-Exhange-Knowledge-Explorer)

## Integration / Use Cases  
* Working with datasets comprised of PDFs is a daunting task, mostly due to trial-and-error of extracting quality text that can be easily used for data science and other analyses. And yet, it is very common for data scientists working on natural language processing to only have access to PDFs as a dataset.
* The post processing methods described here and in the Jupyter Notebooks can:  
	* Serve as a guide to other Data Scientists who may not have access to robust tools for processing PDFs  
	* Be combined to create a flexible command line tool or application for processing PDFs  
	* Provide a tool with which Watson Explorer users could perform targeted processing using the exported facets  
* These methods have broad applicability, but the team hopes the domains benefit:
	* Topic modeling and Natural Language Processing  
	* Heat Exchangers and Materials Science  

## Direction of Future Work
With more time, additional features the team will would like to explore:
* Processing and topic modeling using noun sequences and noun-modifier pairing from Watson Explorer
* Using Excalibur to speed up extracting tables by providing a GUI so users can more easily select relevant regions within PDFs
* Adjusting parameters within Camelot to improve table extraction
* User intuitive interface to for easier PDF cleanup, and improved interface for understanding topic modeling results
* Command line interface to automate PDF cleanup and topic modeling
* Additional comparison and similarity checking. This could include additional unsupervised learning such as word embeddings and word vectors to identify additional similarities between papers.
* Applying PCA or dimensionality reduction as a feature engineering step to improve topic modeling results


## Contributors

* Herb Schilling, GRC, Computer Scientist, [hschilling@nasa.gov](hschilling@nasa.gov)
* Calvin Robinson, GRC, Data Architect, [calvin.r.robinson@nasa.gov](calvin.r.robinson@nasa.gov)
* Evan "Taylor" Yates, MSFC, Software Engineer, [evan.t.yates@nasa.gov](evan.t.yates@nasa.gov)
* Gulsum Oz, ARC, Information Tech Specialist, [oz.gulsum@nasa.gov](oz.gulsum@nasa.gov)
* Shruti Janardhanan, GRC, Intern, [shruti.janardhanan@nasa.gov](shruti.janardhanan@nasa.gov)
* Kelci Mensah, GRC, Intern, [kelci.mensah@nasa.gov](kelci.mensah@nasa.gov)
* Samantha "Sam" Stesch, GRC, Intern, [samantha.g.stesch@nasa.gov](samantha.g.stesch@nasa.gov)
* Alexander Wong, GRC, Intern, [alexander.wong@nasa.gov](alexander.wong@nasa.gov)

## Further Resources
* [LDA Topic Modeling (LARC)](https://visualization.larc.nasa.gov/dash/notebooks/LDA_with_Bokeh)
* [Scikit-Learn Documentation](https://scikit-learn.org/stable/)
* [NLTK Documentation](https://www.nltk.org/)
