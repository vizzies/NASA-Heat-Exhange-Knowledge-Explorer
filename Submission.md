## Challenge A - Paper Clustering  
* The Problem: As the already surging rate of scientific literature publishing continues to grow exponentially,  it has become increasingly difficult and time-consuming for researchers to gather the necessary resources for interdisciplinary cross collaboration, even with the use of current sophisticated search tools (as they do not identify and dsiplay subtopic relations and the extent of research).
* Our Project: The team explored several methods to improve topic modeling results generated by Latent Dirichlet Allocation (LDA). All methods focused on improving the postprocessing and cleaning of PDFs or derived datasets.Â 
* Results:

## Process Overview and Implementation  
* Strategy
* Steps taken to solve problem
* Include critical design and/or implementation decisions

## Dependencies and Outputs  
* Dependencies
	* Generated the.txt version of each PDF
	* [PDF Parser](https://github.com/vizzies/grcml-challenge-a-starter/blob/main/Scripts/batch_pdf_parser.py)
	* [Python Element Tree Parser](https://docs.python.org/3/library/xml.etree.elementtree.html)

* Artifacts (Output) Produced
	* [Combined Output Repository](https://github.com/vizzies/grcml-challenge-a-starter/blob/main/Processed/Combined_Output.txt)

## Integration / Use Cases  
* Broad applications, how can project address other problems (try to abstract function of code/concept and imagine other uses)
* Current NASA projects and/or research campaigns
	* Biomimicry (V.I.N.E.)
	*

## Direction of Future Work
With more time, additional features the team will would like to explore:
* Processing and topic modeling using noun sequences and noun-modifier pairing from Watson Explorer
* Using Excalibur to speed up extracting tables by providing a GUI so users can more easily select relevant regions within PDFs
* Adjusting parameters within Camelot to improve table extraction
* User intuitive interface to for easier PDF cleanup, and improved interface for understanding topic modeling results
* Command line interface to automate PDF cleanup and topic modeling
* Additional comparison and similarity checking. This could include additional unsupervised learning such as word embeddings and word vectors to identify additional similarities between papers.
* Applying PCA or dimensionality reduction as a feature engineering step to improve topic modeling results


## Contributors

* Herb Schilling, GRC, Computer Scientist, [hschilling@nasa.gov](hschilling@nasa.gov)
* Calvin Robinson, GRC, Data Architect, [calvin.r.robinson@nasa.gov](calvin.r.robinson@nasa.gov)
* Evan "Taylor" Yates, MSFC, Software Engineer, [evan.t.yates@nasa.gov](evan.t.yates@nasa.gov)
* Gulsum Oz, ARC, Information Tech Specialist, [oz.gulsum@nasa.gov](oz.gulsum@nasa.gov)
* Shruti Janardhanan, GRC, Intern, [shruti.janardhanan@nasa.gov](shruti.janardhanan@nasa.gov)
* Kelci Mensah, GRC, Intern, [kelci.mensah@nasa.gov](kelci.mensah@nasa.gov)
* Samantha "Sam" Stesch, GRC, Intern, [samantha.g.stesch@nasa.gov](samantha.g.stesch@nasa.gov)
* Alexander Wong, GRC, Intern, [alexander.wong@nasa.gov](alexander.wong@nasa.gov)

## Further Resources
* [LDA Topic Modeling (LARC)](https://visualization.larc.nasa.gov/dash/notebooks/LDA_with_Bokeh)
* [Scikit-Learn Documentation](https://scikit-learn.org/stable/)
* [NLTK Documentation](https://www.nltk.org/)
